emb_dim: 128
max_seq_length: 50
layer_num: 8
n_heads: 4


num_epoch: 5
batch_size: 128
learning_rate: 0.0001
dropout: 0.2

