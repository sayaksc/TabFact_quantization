emb_dim: 64
max_seq_length: 50
layer_num: 4
n_heads: 4


num_epoch: 10
batch_size: 512
learning_rate: 0.0001
dropout: 0.2

